# MDP Flow
Time t=0 에서의 State를 $`s_{\text{0}}`$, Policy의 Action을 $`Policy(s_{\text{0}}) = a_{\text{0}}`$ 하자  
그러면 Reward를 $`R_{\text{0}} = R^{a_0}_{s_0} = E[R_1 | S = s_0, A =a_0]`$ 로 정의할 수 있다.
